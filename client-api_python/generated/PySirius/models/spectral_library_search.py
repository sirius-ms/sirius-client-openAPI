# coding: utf-8

"""
    SIRIUS Nightsky API


    Generated by OpenAPI Generator (https://openapi-generator.tech)

    Do not edit the class manually.
"""  # noqa: E501


from __future__ import annotations
import pprint
import re  # noqa: F401
import json

from pydantic import BaseModel, ConfigDict, Field, StrictBool, StrictInt, StrictStr
from typing import Any, ClassVar, Dict, List, Optional
from PySirius.models.spectral_matching_type import SpectralMatchingType
from typing import Optional, Set
from typing_extensions import Self

class SpectralLibrarySearch(BaseModel):
    """
    User/developer friendly parameter subset for the Spectral library search tool.
    """ # noqa: E501
    enabled: Optional[StrictBool] = Field(default=None, description="tags whether the tool is enabled")
    spectra_search_dbs: Optional[List[StrictStr]] = Field(default=None, description="Structure Databases with Reference spectra to search in.  <p>  Defaults to BIO + Custom Databases. Possible values are available to Database API.", alias="spectraSearchDBs")
    precursor_deviation_ppm: Optional[float] = Field(default=None, description="Maximum allowed mass deviation in ppm for matching the precursor. If not specified, the same value as for the peaks is used.", alias="precursorDeviationPpm")
    min_similarity: Optional[float] = Field(default=None, description="Minimal spectral similarity of a spectral match to be considered a hit.", alias="minSimilarity")
    min_num_of_peaks: Optional[StrictInt] = Field(default=None, description="Minimal number of matching peaks of a spectral match to be considered a hit.", alias="minNumOfPeaks")
    enable_analogue_search: Optional[StrictBool] = Field(default=None, description="Enable analogue search in addition to the identity spectral library search", alias="enableAnalogueSearch")
    min_similarity_analogue: Optional[float] = Field(default=None, description="Minimal spectral similarity of a spectral match to be considered an analogue hit.", alias="minSimilarityAnalogue")
    min_num_of_peaks_analogue: Optional[StrictInt] = Field(default=None, description="Minimal number of matching peaks of a spectral match to be considered an analogue hit.", alias="minNumOfPeaksAnalogue")
    scoring: Optional[SpectralMatchingType] = Field(default=None, description="NO LONGER SUPPORTED (IGNORED)  Specify scoring method to match spectra  INTENSITY: Intensity weighted. Each peak matches at most one peak in the other spectrum.  GAUSSIAN: Treat peaks as (un-normalized) Gaussians and score overlapping areas of PDFs. Each peak might score against multiple peaks in the other spectrum.  MODIFIED_COSINE:  This algorithm requires that there is at most one pair of peaks (u,v) where the m/z of u and v are within the allowed mass tolerance. To be used for analog search with different precursor masses.")
    peak_deviation_ppm: Optional[float] = Field(default=None, description="NO LONGER SUPPORTED (IGNORED)  Maximum allowed mass deviation in ppm for matching peaks.", alias="peakDeviationPpm")
    __properties: ClassVar[List[str]] = ["enabled", "spectraSearchDBs", "precursorDeviationPpm", "minSimilarity", "minNumOfPeaks", "enableAnalogueSearch", "minSimilarityAnalogue", "minNumOfPeaksAnalogue", "scoring", "peakDeviationPpm"]

    model_config = ConfigDict(
        populate_by_name=True,
        validate_assignment=True,
        protected_namespaces=(),
    )


    def to_str(self) -> str:
        """Returns the string representation of the model using alias"""
        return pprint.pformat(self.model_dump(by_alias=True))

    def to_json(self) -> str:
        """Returns the JSON representation of the model using alias"""
        # TODO: pydantic v2: use .model_dump_json(by_alias=True, exclude_unset=True) instead
        return json.dumps(self.to_dict())

    @classmethod
    def from_json(cls, json_str: str) -> Optional[Self]:
        """Create an instance of SpectralLibrarySearch from a JSON string"""
        return cls.from_dict(json.loads(json_str))

    def to_dict(self) -> Dict[str, Any]:
        """Return the dictionary representation of the model using alias.

        This has the following differences from calling pydantic's
        `self.model_dump(by_alias=True)`:

        * `None` is only added to the output dict for nullable fields that
          were set at model initialization. Other fields with value `None`
          are ignored.
        """
        excluded_fields: Set[str] = set([
        ])

        _dict = self.model_dump(
            by_alias=True,
            exclude=excluded_fields,
            exclude_none=True,
        )
        return _dict

    @classmethod
    def from_dict(cls, obj: Optional[Dict[str, Any]]) -> Optional[Self]:
        """Create an instance of SpectralLibrarySearch from a dict"""
        if obj is None:
            return None

        if not isinstance(obj, dict):
            return cls.model_validate(obj)

        _obj = cls.model_validate({
            "enabled": obj.get("enabled"),
            "spectraSearchDBs": obj.get("spectraSearchDBs"),
            "precursorDeviationPpm": obj.get("precursorDeviationPpm"),
            "minSimilarity": obj.get("minSimilarity"),
            "minNumOfPeaks": obj.get("minNumOfPeaks"),
            "enableAnalogueSearch": obj.get("enableAnalogueSearch"),
            "minSimilarityAnalogue": obj.get("minSimilarityAnalogue"),
            "minNumOfPeaksAnalogue": obj.get("minNumOfPeaksAnalogue"),
            "scoring": obj.get("scoring"),
            "peakDeviationPpm": obj.get("peakDeviationPpm")
        })
        return _obj


